{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ´ MTG Card Recognition System\n",
        "\n",
        "**Approach:** Perceptual Hashing\n",
        "**Dataset:** Scryfall API\n",
        "**Max Cards:** 10000\n",
        "\n",
        "This notebook implements a Magic: The Gathering card recognition system that can identify cards regardless of language or artwork variant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install opencv-python pillow requests tqdm imagehash\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import requests\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import imagehash\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching up to 10000 cards from Scryfall...\n",
            "Fetched 10000 cards\n",
            "Total cards collected: 10000\n"
          ]
        }
      ],
      "source": [
        "def fetch_scryfall_cards(max_cards=10000):\n",
        "    \"\"\"\n",
        "    Fetch card data from Scryfall API.\n",
        "    Returns a list of card objects with image URLs and metadata.\n",
        "    \"\"\"\n",
        "    print(f'Fetching up to {max_cards} cards from Scryfall...')\n",
        "    \n",
        "    cards = []\n",
        "    url = 'https://api.scryfall.com/cards/search?q=game:paper'\n",
        "    \n",
        "    while url and len(cards) < max_cards:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            print(f'Error: {response.status_code}')\n",
        "            break\n",
        "            \n",
        "        data = response.json()\n",
        "        \n",
        "        for card in data['data']:\n",
        "            if 'image_uris' in card:\n",
        "                cards.append({\n",
        "                    'id': card['id'],\n",
        "                    'name': card['name'],\n",
        "                    'image_url': card['image_uris']['normal'],\n",
        "                    'set': card.get('set', 'unknown'),\n",
        "                    'collector_number': card.get('collector_number', '0')\n",
        "                })\n",
        "                \n",
        "                if len(cards) >= max_cards:\n",
        "                    break\n",
        "        \n",
        "        url = data.get('next_page')\n",
        "        time.sleep(0.1)  # Respect API rate limits\n",
        "    \n",
        "    print(f'Fetched {len(cards)} cards')\n",
        "    return cards\n",
        "\n",
        "# Fetch the cards\n",
        "cards_data = fetch_scryfall_cards()\n",
        "print(f'Total cards collected: {len(cards_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Card Detection (OpenCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Card detection function ready\n"
          ]
        }
      ],
      "source": [
        "def detect_card(image):\n",
        "    \"\"\"\n",
        "    Detect and extract a card from an image.\n",
        "    Returns the cropped and perspective-corrected card image.\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    # Threshold\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    \n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    if not contours:\n",
        "        return None\n",
        "    \n",
        "    # Find largest rectangular contour\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    \n",
        "    # Approximate to polygon\n",
        "    epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
        "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
        "    \n",
        "    # If we found a quadrilateral\n",
        "    if len(approx) == 4:\n",
        "        # Get card dimensions (standard MTG card ratio: 2.5:3.5)\n",
        "        width, height = 250, 350\n",
        "        \n",
        "        # Destination points\n",
        "        dst_pts = np.array([\n",
        "            [0, 0],\n",
        "            [width - 1, 0],\n",
        "            [width - 1, height - 1],\n",
        "            [0, height - 1]\n",
        "        ], dtype='float32')\n",
        "        \n",
        "        # Source points\n",
        "        src_pts = approx.reshape(4, 2).astype('float32')\n",
        "        \n",
        "        # Calculate perspective transform\n",
        "        M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "        \n",
        "        # Apply transform\n",
        "        warped = cv2.warpPerspective(image, M, (width, height))\n",
        "        \n",
        "        return warped\n",
        "    \n",
        "    return None\n",
        "\n",
        "print('Card detection function ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Extraction & Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building hash database...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [35:21<00:00,  4.71it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hash database built with 9997 cards\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def build_hash_database(cards_data):\n",
        "    \"\"\"\n",
        "    Build a database of perceptual hashes for all cards.\n",
        "    \"\"\"\n",
        "    hash_db = {}\n",
        "    \n",
        "    print('Building hash database...')\n",
        "    for card in tqdm(cards_data):\n",
        "        try:\n",
        "            # Download image\n",
        "            response = requests.get(card['image_url'])\n",
        "            img = Image.open(requests.get(card['image_url'], stream=True).raw)\n",
        "            \n",
        "            # Calculate perceptual hash\n",
        "            img_hash = imagehash.phash(img)\n",
        "            \n",
        "            # Store in database\n",
        "            hash_db[str(img_hash)] = card\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {card['name']}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return hash_db\n",
        "\n",
        "def recognize_card(query_image, hash_db, threshold=5):\n",
        "    \"\"\"\n",
        "    Recognize a card using perceptual hashing.\n",
        "    Returns the best match if distance < threshold.\n",
        "    \"\"\"\n",
        "    # Convert to PIL Image if needed\n",
        "    if isinstance(query_image, np.ndarray):\n",
        "        query_image = Image.fromarray(cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB))\n",
        "    \n",
        "    # Calculate hash\n",
        "    query_hash = imagehash.phash(query_image)\n",
        "    \n",
        "    # Find best match\n",
        "    best_match = None\n",
        "    best_distance = float('inf')\n",
        "    \n",
        "    for hash_str, card_data in hash_db.items():\n",
        "        distance = query_hash - imagehash.hex_to_hash(hash_str)\n",
        "        \n",
        "        if distance < best_distance:\n",
        "            best_distance = distance\n",
        "            best_match = card_data\n",
        "    \n",
        "    if best_distance <= threshold:\n",
        "        return best_match, best_distance\n",
        "    \n",
        "    return None, best_distance\n",
        "\n",
        "# Build the database\n",
        "hash_database = build_hash_database(cards_data)\n",
        "print(f'Hash database built with {len(hash_database)} cards')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Complete Recognition Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete pipeline ready!\n",
            "Usage: result, info = identify_mtg_card(\"path/to/card/image.jpg\")\n"
          ]
        }
      ],
      "source": [
        "def identify_mtg_card(image_path):\n",
        "    \"\"\"\n",
        "    Complete pipeline: load image -> detect card -> recognize.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    \n",
        "    if image is None:\n",
        "        return None, 'Failed to load image'\n",
        "    \n",
        "    # Detect card\n",
        "    detected_card = detect_card(image)\n",
        "    \n",
        "    if detected_card is None:\n",
        "        print('No card detected, using full image')\n",
        "        detected_card = image\n",
        "    \n",
        "    # Recognize card\n",
        "    result, distance = recognize_card(detected_card, hash_database)\n",
        "    \n",
        "    if result:\n",
        "        return result, f'Match found with distance: {distance}'\n",
        "    else:\n",
        "        return None, f'No match found (best distance: {distance})'\n",
        "\n",
        "print('Complete pipeline ready!')\n",
        "print('Usage: result, info = identify_mtg_card(\"path/to/card/image.jpg\")')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Testing & Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identification failed: No match found (best distance: 14)\n"
          ]
        }
      ],
      "source": [
        "test_image_path = 'img/atraxa.jpg'\n",
        "\n",
        "# Uncomment to test:\n",
        "result, info = identify_mtg_card(test_image_path)\n",
        "if result:\n",
        "    print(f\"Card identified: {result['name']}\")\n",
        "    print(f\"Set: {result['set']}\")\n",
        "    print(info)\n",
        "else:\n",
        "    print(f\"Identification failed: {info}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visualization function ready\n"
          ]
        }
      ],
      "source": [
        "def visualize_result(image_path, result, info):\n",
        "    \"\"\"\n",
        "    Visualize the recognition result.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    \n",
        "    # Original image\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axes[0].imshow(img_rgb)\n",
        "    axes[0].set_title('Input Image')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Matched card\n",
        "    if result:\n",
        "        matched_img = Image.open(requests.get(result['image_url'], stream=True).raw)\n",
        "        axes[1].imshow(matched_img)\n",
        "        axes[1].set_title(f\"Matched: {result['name']}\\n{info}\")\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No match found', ha='center', va='center')\n",
        "        axes[1].set_title(info)\n",
        "    \n",
        "    axes[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print('Visualization function ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation function ready\n"
          ]
        }
      ],
      "source": [
        "def evaluate_accuracy(test_images, ground_truth):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of the recognition system.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = len(test_images)\n",
        "    \n",
        "    for img_path, true_card_id in zip(test_images, ground_truth):\n",
        "        result, _ = identify_mtg_card(img_path)\n",
        "        \n",
        "        if result and result['id'] == true_card_id:\n",
        "            correct += 1\n",
        "    \n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy: {accuracy:.2%} ({correct}/{total})')\n",
        "    return accuracy\n",
        "\n",
        "print('Evaluation function ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Next Steps\n",
        "\n",
        "### To use this notebook:\n",
        "\n",
        "1. **Run all cells** to initialize the system\n",
        "2. **Wait for database building** (may take 10-30 minutes depending on card count)\n",
        "3. **Test with your images** using `identify_mtg_card(image_path)`\n",
        "\n",
        "### Improvements to consider:\n",
        "\n",
        "- Add caching to save the hash database locally\n",
        "- Implement batch processing for multiple cards\n",
        "- Add support for double-faced cards\n",
        "- Create a web interface using Gradio or Streamlit\n",
        "- Fine-tune detection for specific lighting conditions\n",
        "\n",
        "### Performance notes:\n",
        "\n",
        "- **Perceptual Hash**: ~50-100ms per card, works well with variations\n",
        "\n",
        "Happy card hunting! ðŸŽ´âœ¨"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
